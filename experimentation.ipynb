{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathToFile = r\"./fb-dataset/Training/\"\n",
    "fileName = 'Features_Variant_5.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tarfile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv(\"./dataset/Training/\" + fileName) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:,:-1]\n",
    "y = data.iloc[:,-1:]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "linear reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "         normalize=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = lin_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27.679928761371432"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "rms = sqrt(mean_squared_error(y_test, y_predicted))\n",
    "rms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "polynomial reg w grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 4 candidates, totalling 40 fits\n",
      "[CV] polynomialfeatures__degree=3 ....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def PolynomialRegression(degree=2, **kwargs):\n",
    "    return make_pipeline(PolynomialFeatures(degree), LinearRegression(**kwargs))\n",
    "\n",
    "param_grid = {'polynomialfeatures__degree': np.arange([1,2,3])}\n",
    "\n",
    "poly_grid = GridSearchCV(PolynomialRegression(), param_grid, \n",
    "                         cv=10, \n",
    "                         scoring='neg_mean_squared_error', \n",
    "                         verbose=3) \n",
    "poly_grid.fit(X_train, y_train)\n",
    "poly_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly_features = PolynomialFeatures(degree=2, include_bias=False)\n",
    "X_poly = poly_features.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.69242617]),\n",
       " array([[ 9.82997433e-03, -2.51912168e-03, -1.68012130e-05, ...,\n",
       "         -4.65910122e-03,  0.00000000e+00, -1.47285455e-03]]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_poly, y_train)\n",
    "lin_reg.intercept_, lin_reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_poly = poly_features.fit_transform(X_test)\n",
    "y_predicted = lin_reg.predict(X_test_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24.411350282267513"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "rms = sqrt(mean_squared_error(y_test, y_predicted))\n",
    "rms\n",
    "# 2 => 24.411350282267513"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "tree_reg = DecisionTreeRegressor(max_depth=5, random_state=42)\n",
    "tree_reg.fit(X_train, y_train)\n",
    "y_predicted = tree_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22.015716916047406"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "rms = sqrt(mean_squared_error(y_test, y_predicted))\n",
    "rms\n",
    "#5 22.015716916047406"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:5: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rnd_clf = RandomForestRegressor(max_depth=16, random_state=0,\n",
    "                                  n_estimators=100)\n",
    "rnd_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = rnd_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.88831831046764"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "rms = sqrt(mean_squared_error(y_test, y_pred_rf))\n",
    "rms\n",
    "#max_depth=5 20.362940311947305\n",
    "#max_depth=7 19.201973177589892\n",
    "#max_depth=10 18.35146117332676\n",
    "#max_depth=15 17.980892468540784\n",
    "#max_depth=16 17.88831831046764\n",
    "#max_depth=17 17.934805696660312\n",
    "#max_depth=20 17.973922197807664\n",
    "#max_depth=40 17.925442316420703"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.34340577e-02, 7.79598736e-03, 1.17666550e-02, 8.68052503e-03,\n",
       "       2.55599488e-04, 1.18824856e-02, 1.35388625e-02, 8.70835968e-03,\n",
       "       1.13843365e-02, 2.41272279e-04, 3.50894762e-03, 2.35677405e-02,\n",
       "       1.40778572e-02, 1.13743194e-02, 5.77096611e-08, 4.66325597e-03,\n",
       "       2.46306252e-02, 9.17354342e-03, 9.35974372e-03, 2.70066033e-04,\n",
       "       4.76463828e-03, 1.67778873e-02, 9.84919038e-03, 5.99103599e-03,\n",
       "       6.59019113e-03, 4.04524007e-03, 1.03340469e-02, 7.08582725e-03,\n",
       "       9.51294586e-03, 2.43311654e-02, 2.78915727e-01, 7.24172769e-04,\n",
       "       2.53284479e-02, 5.29617072e-02, 2.14237132e-01, 2.31313053e-02,\n",
       "       8.63702742e-02, 0.00000000e+00, 3.84884972e-04, 2.02928921e-03,\n",
       "       2.38673596e-03, 4.26702827e-03, 2.26880500e-03, 1.08874971e-03,\n",
       "       1.66696956e-03, 1.40762928e-03, 2.16522048e-03, 2.01609822e-03,\n",
       "       2.29514026e-03, 3.41322332e-03, 2.21262270e-03, 1.61202327e-03,\n",
       "       1.52034687e-03])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_clf.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gradient boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=1.0, loss='ls', max_depth=5, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=3, n_iter_no_change=None, presort='auto',\n",
       "             random_state=42, subsample=1.0, tol=0.0001,\n",
       "             validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "gbrt = GradientBoostingRegressor(max_depth=5, n_estimators=3, learning_rate=1.0, random_state=42)\n",
    "gbrt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = gbrt.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.87836667989657"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "rms = sqrt(mean_squared_error(y_test, y_predicted))\n",
    "rms\n",
    "#max_depth=4 22.266818232014103\n",
    "#max_depth=5 20.87836667989657\n",
    "#max_depth=6 22.364510091676358\n",
    "#max_depth=15 24.02494817242046"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "neural net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import StandardScaler "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:6: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  \n",
      "/usr/local/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 415.34195374\n",
      "Validation score: 0.380607\n",
      "Iteration 2, loss = 355.80373512\n",
      "Validation score: 0.439664\n",
      "Iteration 3, loss = 333.51795489\n",
      "Validation score: 0.466995\n",
      "Iteration 4, loss = 317.49944700\n",
      "Validation score: 0.483612\n",
      "Iteration 5, loss = 302.40319771\n",
      "Validation score: 0.500880\n",
      "Iteration 6, loss = 290.51590764\n",
      "Validation score: 0.514136\n",
      "Iteration 7, loss = 281.11621291\n",
      "Validation score: 0.531813\n",
      "Iteration 8, loss = 273.35815878\n",
      "Validation score: 0.546351\n",
      "Iteration 9, loss = 267.36428305\n",
      "Validation score: 0.515890\n",
      "Iteration 10, loss = 265.13037996\n",
      "Validation score: 0.554115\n",
      "Iteration 11, loss = 257.78641725\n",
      "Validation score: 0.502531\n",
      "Iteration 12, loss = 251.50485317\n",
      "Validation score: 0.556069\n",
      "Iteration 13, loss = 246.80378178\n",
      "Validation score: 0.577277\n",
      "Iteration 14, loss = 242.26042053\n",
      "Validation score: 0.581165\n",
      "Iteration 15, loss = 245.42809699\n",
      "Validation score: 0.579619\n",
      "Iteration 16, loss = 238.00933214\n",
      "Validation score: 0.586165\n",
      "Iteration 17, loss = 232.62456419\n",
      "Validation score: 0.596737\n",
      "Iteration 18, loss = 229.38897411\n",
      "Validation score: 0.601218\n",
      "Iteration 19, loss = 226.34318706\n",
      "Validation score: 0.588615\n",
      "Iteration 20, loss = 220.25195441\n",
      "Validation score: 0.610046\n",
      "Iteration 21, loss = 222.28861183\n",
      "Validation score: 0.609325\n",
      "Iteration 22, loss = 216.21241751\n",
      "Validation score: 0.615459\n",
      "Iteration 23, loss = 216.34977277\n",
      "Validation score: 0.587209\n",
      "Iteration 24, loss = 212.30052692\n",
      "Validation score: 0.607488\n",
      "Iteration 25, loss = 212.58958162\n",
      "Validation score: 0.618601\n",
      "Iteration 26, loss = 208.91273384\n",
      "Validation score: 0.612368\n",
      "Iteration 27, loss = 202.69661522\n",
      "Validation score: 0.608428\n",
      "Iteration 28, loss = 204.78691857\n",
      "Validation score: 0.625454\n",
      "Iteration 29, loss = 205.86982419\n",
      "Validation score: 0.594396\n",
      "Iteration 30, loss = 199.88977459\n",
      "Validation score: 0.602968\n",
      "Iteration 31, loss = 198.33905786\n",
      "Validation score: 0.586657\n",
      "Iteration 32, loss = 196.73613259\n",
      "Validation score: 0.634703\n",
      "Iteration 33, loss = 196.61167999\n",
      "Validation score: 0.637942\n",
      "Iteration 34, loss = 190.84752237\n",
      "Validation score: 0.642048\n",
      "Iteration 35, loss = 194.79355518\n",
      "Validation score: 0.648553\n",
      "Iteration 36, loss = 196.48683952\n",
      "Validation score: 0.637568\n",
      "Iteration 37, loss = 191.60711364\n",
      "Validation score: 0.649601\n",
      "Iteration 38, loss = 188.56463442\n",
      "Validation score: 0.642795\n",
      "Iteration 39, loss = 184.27993151\n",
      "Validation score: 0.574673\n",
      "Iteration 40, loss = 184.24857295\n",
      "Validation score: 0.641025\n",
      "Iteration 41, loss = 187.35742046\n",
      "Validation score: 0.630348\n",
      "Iteration 42, loss = 183.19898829\n",
      "Validation score: 0.645100\n",
      "Iteration 43, loss = 183.15580799\n",
      "Validation score: 0.658371\n",
      "Iteration 44, loss = 181.18204701\n",
      "Validation score: 0.653288\n",
      "Iteration 45, loss = 179.14593226\n",
      "Validation score: 0.591291\n",
      "Iteration 46, loss = 182.63093883\n",
      "Validation score: 0.656613\n",
      "Iteration 47, loss = 179.40268090\n",
      "Validation score: 0.656039\n",
      "Iteration 48, loss = 174.41372414\n",
      "Validation score: 0.632023\n",
      "Iteration 49, loss = 173.83074823\n",
      "Validation score: 0.601272\n",
      "Iteration 50, loss = 170.75699992\n",
      "Validation score: 0.650686\n",
      "Iteration 51, loss = 174.86879864\n",
      "Validation score: 0.645090\n",
      "Iteration 52, loss = 173.38336323\n",
      "Validation score: 0.671347\n",
      "Iteration 53, loss = 170.00289209\n",
      "Validation score: 0.482801\n",
      "Iteration 54, loss = 171.23552197\n",
      "Validation score: 0.674923\n",
      "Iteration 55, loss = 168.02853401\n",
      "Validation score: 0.676034\n",
      "Iteration 56, loss = 172.54043671\n",
      "Validation score: 0.653243\n",
      "Iteration 57, loss = 171.22290969\n",
      "Validation score: 0.669312\n",
      "Iteration 58, loss = 166.84759771\n",
      "Validation score: 0.669059\n",
      "Iteration 59, loss = 165.04860097\n",
      "Validation score: 0.664814\n",
      "Iteration 60, loss = 166.53416461\n",
      "Validation score: 0.671539\n",
      "Iteration 61, loss = 166.08705868\n",
      "Validation score: 0.654701\n",
      "Iteration 62, loss = 165.68872684\n",
      "Validation score: 0.648680\n",
      "Iteration 63, loss = 161.86953399\n",
      "Validation score: 0.673208\n",
      "Iteration 64, loss = 162.15805443\n",
      "Validation score: 0.671049\n",
      "Iteration 65, loss = 159.70260540\n",
      "Validation score: 0.663144\n",
      "Iteration 66, loss = 169.11456148\n",
      "Validation score: 0.604066\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "classifier = MLPRegressor(alpha = 1e-4, hidden_layer_sizes = (150,5,), \n",
    "random_state = 12, max_iter = 500, activation = 'relu',\n",
    "verbose = True, early_stopping = True, learning_rate_init = 0.001)\n",
    "mlp = classifier.fit(scaler.transform(X_train), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:4: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20.541230943521477"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "predict_labels = mlp.predict(scaler.transform(X_test))\n",
    "rms = sqrt(mean_squared_error(y_test, predict_labels))\n",
    "rms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
